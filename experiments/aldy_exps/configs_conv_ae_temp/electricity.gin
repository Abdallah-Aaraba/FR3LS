build.experiment_name = 'aldy_exps'

# Ensemble parameters
build.ts_dataset_name = 'electricity'
build.repeats = 1

build.parameters = {'train_mode': ['PRETRAINED'], 'f_model_type': ['LSTM_ParamGEN'], 'batch_size': [4], 'non_overlap_batch': [24], 'learning_rate': [0.0001], 'lambda2': [0.5], 'lambda3': [0.15], 'f_alpha': [0.01], 'ts2vec_depth': [8], 'alt_epoch_nbr': [750]}

instance.train_window = 388  # train_window = 2 * f_input_window
instance.f_input_window = 194  # 8.0833 days (was 1 week)
instance.f_out_same_in_size = False  # Forecast only the last value
instance.horizon = 24  # 1 day
#### instance.non_overlap_batch = 6
instance.n_test_windows = 7  # 7 days of testing
instance.n_val_windows = 2  # 0 days of validation
instance.shuffle = False

#### instance.f_model_type = 'TCN_Parameterized'
instance.f_num_shared_channels = [16, 16, 16, 16, 16, 16]  # Decrease number of layers and increase kernel size
instance.f_nbr_param_layers = 1  # If it doesn't work, set this to 1  # TODO: This was 1 !!!
instance.f_kernel_size = 3  # f_kernel_size increased from 2 to 3
instance.f_dropout = 0.0
instance.f_leveld_init = True
instance.f_implicit_batching = True

instance.f_hidden_size = 32
instance.f_num_layers = 4

instance.ae_hidden_dims = [96, 64, 32, 32, 64, 96]

instance.f_model_path = 'repeat=0,f_model_type=LSTM_Modified,batch_size=1,learning_rate=0.0001,non_overlap_batch=24,n_val_windows=2'
instance.ts2vec_path = 'repeat=0,f_model_type=LSTM_Modified,batch_size=8,non_overlap_batch=24,learning_rate=0.0001,ts2vec_depth=8'

instance.ts2vec_output_dims = 32
instance.ts2vec_hidden_dims = 16
#### instance.ts2vec_depth = 4
instance.ts2vec_mask_mode = 'binomial'

instance.activation = 'relu'
instance.train_loss_name = 'ALDY'
instance.val_loss_name = 'MAPE'
instance.lambda1 = 1
#### instance.lambda2 = 0.5
#### instance.lambda3 = 0.25
instance.train_ae_loss = 'MAE'
instance.train_forecasting_loss ='MSE'

instance.epochs = 750
instance.epochs_TLAE = 750
instance.epochs_TS2VEC = 200
instance.epochs_ParamGen = 200
instance.iterations = 150
#### instance.alt_epoch_nbr = 200
#### instance.batch_size = 4
instance.random_state = 42
#### instance.learning_rate = 0.0001
instance.verbose = True
instance.early_stopping = False
instance.patience = 200

